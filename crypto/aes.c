//https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197-upd1.pdf
#include <stdint.h>
#include <stdlib.h>
#include <stdio.h>
#include <endian.h>
#include <string.h>
#include "include/aes.h"
// all aes functions, and all galois_... functions, work in galois field of 2^8 order

#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
#warning "This aes implementation is untested on big endian, probably doesn't work"
#endif

static inline uint8_t galois_add(uint8_t a, uint8_t b) {
    return a^b;
}

static inline uint8_t galois_xTimes(uint8_t b) {
    return b&0b10000000?(((uint8_t)(b<<1))^0b00011011):((uint8_t)(b<<1));
}

//static inline uint8_t galois_mult(uint8_t x, uint8_t a) { // exact implementation from fips 197, not very effective
//    uint8_t res = (a&1)?x:0;
//    uint8_t temp = 0;
//    for (int i = 1; i < 8; i++) {
//        if (a & (1<<i)) {
//            temp = x;
//            for (int j = 0; j < i; j++) { // repeated application of xTimes, see page 9
//                temp = galois_xTimes(temp);
//            }
//            res = galois_add(res, temp);
//        }
//    }
//    return res;
//}

static inline uint8_t galois_mult(uint8_t x, uint8_t a) { // TODO: consider unrolling the loop for **speed**
    // basically the same as the previous, but because the power gets bigger, we can do the for j while we go resulting in us not needing the for j at all, simplifying to most 8 iterations
    // post writing this i found out this is supposedly called russian peasant(????)
    uint8_t out = 0;
    for (int i = 0; i < 8; i++) {
        //if (a == 0) break; // good idea but considering branch misprediction penalty, probably not really worth it
        if (a&1) out = galois_add(out, x);
        x = galois_xTimes(x);
        a >>= 1;
    }
    return out;
}


//static inline uint8_t galois_inverse(uint8_t x) { // see page 10(18)
//    if (x == 0) return 0;
//    uint8_t temp = x;
//    for (int i = 1; i < 254; i++) {
//        temp = galois_mult(temp, x);
//    }
//    return temp;
//}
static const uint8_t aes_mult_inv_lookup[256] = { // pregenerated by galois_inverse
    0x00, 0x01, 0x8d, 0xf6, 0xcb, 0x52, 0x7b, 0xd1, 0xe8, 0x4f, 0x29, 0xc0, 0xb0, 0xe1, 0xe5, 0xc7, 
    0x74, 0xb4, 0xaa, 0x4b, 0x99, 0x2b, 0x60, 0x5f, 0x58, 0x3f, 0xfd, 0xcc, 0xff, 0x40, 0xee, 0xb2, 
    0x3a, 0x6e, 0x5a, 0xf1, 0x55, 0x4d, 0xa8, 0xc9, 0xc1, 0x0a, 0x98, 0x15, 0x30, 0x44, 0xa2, 0xc2, 
    0x2c, 0x45, 0x92, 0x6c, 0xf3, 0x39, 0x66, 0x42, 0xf2, 0x35, 0x20, 0x6f, 0x77, 0xbb, 0x59, 0x19, 
    0x1d, 0xfe, 0x37, 0x67, 0x2d, 0x31, 0xf5, 0x69, 0xa7, 0x64, 0xab, 0x13, 0x54, 0x25, 0xe9, 0x09, 
    0xed, 0x5c, 0x05, 0xca, 0x4c, 0x24, 0x87, 0xbf, 0x18, 0x3e, 0x22, 0xf0, 0x51, 0xec, 0x61, 0x17, 
    0x16, 0x5e, 0xaf, 0xd3, 0x49, 0xa6, 0x36, 0x43, 0xf4, 0x47, 0x91, 0xdf, 0x33, 0x93, 0x21, 0x3b, 
    0x79, 0xb7, 0x97, 0x85, 0x10, 0xb5, 0xba, 0x3c, 0xb6, 0x70, 0xd0, 0x06, 0xa1, 0xfa, 0x81, 0x82, 
    0x83, 0x7e, 0x7f, 0x80, 0x96, 0x73, 0xbe, 0x56, 0x9b, 0x9e, 0x95, 0xd9, 0xf7, 0x02, 0xb9, 0xa4, 
    0xde, 0x6a, 0x32, 0x6d, 0xd8, 0x8a, 0x84, 0x72, 0x2a, 0x14, 0x9f, 0x88, 0xf9, 0xdc, 0x89, 0x9a, 
    0xfb, 0x7c, 0x2e, 0xc3, 0x8f, 0xb8, 0x65, 0x48, 0x26, 0xc8, 0x12, 0x4a, 0xce, 0xe7, 0xd2, 0x62, 
    0x0c, 0xe0, 0x1f, 0xef, 0x11, 0x75, 0x78, 0x71, 0xa5, 0x8e, 0x76, 0x3d, 0xbd, 0xbc, 0x86, 0x57, 
    0x0b, 0x28, 0x2f, 0xa3, 0xda, 0xd4, 0xe4, 0x0f, 0xa9, 0x27, 0x53, 0x04, 0x1b, 0xfc, 0xac, 0xe6, 
    0x7a, 0x07, 0xae, 0x63, 0xc5, 0xdb, 0xe2, 0xea, 0x94, 0x8b, 0xc4, 0xd5, 0x9d, 0xf8, 0x90, 0x6b, 
    0xb1, 0x0d, 0xd6, 0xeb, 0xc6, 0x0e, 0xcf, 0xad, 0x08, 0x4e, 0xd7, 0xe3, 0x5d, 0x50, 0x1e, 0xb3, 
    0x5b, 0x23, 0x38, 0x34, 0x68, 0x46, 0x03, 0x8c, 0xdd, 0x9c, 0x7d, 0xa0, 0xcd, 0x1a, 0x41, 0x1c,
};
static inline uint8_t galois_inverse(uint8_t x) {return aes_mult_inv_lookup[x];} // stub function to keep readability

static const uint8_t aes_sbox_lookup[256] = {
    0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,
    0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,
    0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,
    0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,
    0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,
    0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,
    0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,
    0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,
    0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,
    0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,
    0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,
    0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,
    0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,
    0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,
    0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,
    0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
};

#define AES_STATE_W 4

static inline void galois_fixed_mat_mult(uint8_t in[AES_WORD_SIZE], uint8_t out[AES_WORD_SIZE], const uint8_t matrix_word[AES_WORD_SIZE]) {
    // in = b
    // out = d
    // matrix_word = a
    // fully aware not really readable, this is the exact thing from page 10(18)
    /*
        d0   a0 a3 a2 a1   b0
        d1 = a1 a0 a3 a2 * b1
        d2   a2 a1 a0 a3   b2
        d3   a3 a2 a1 a0   b3
    */
    out[0] = galois_mult(matrix_word[0], in[0]) ^ galois_mult(matrix_word[3], in[1]) ^ galois_mult(matrix_word[2], in[2]) ^ galois_mult(matrix_word[1], in[3]);
    out[1] = galois_mult(matrix_word[1], in[0]) ^ galois_mult(matrix_word[0], in[1]) ^ galois_mult(matrix_word[3], in[2]) ^ galois_mult(matrix_word[2], in[3]);
    out[2] = galois_mult(matrix_word[2], in[0]) ^ galois_mult(matrix_word[1], in[1]) ^ galois_mult(matrix_word[0], in[2]) ^ galois_mult(matrix_word[3], in[3]);
    out[3] = galois_mult(matrix_word[3], in[0]) ^ galois_mult(matrix_word[2], in[1]) ^ galois_mult(matrix_word[1], in[2]) ^ galois_mult(matrix_word[0], in[3]);
}

static inline void aes_bytes_to_state(uint8_t state_out[AES_STATE_W][AES_STATE_W], const uint8_t in[AES_BLOCK_SIZE]) {
    for (int r = 0; r < AES_STATE_W; r++) {
        for (int c = 0; c < AES_STATE_W; c++) {
            state_out[r][c] = in[r+AES_STATE_W*c];
        }
    }
}

static inline void aes_state_to_bytes(const uint8_t state_in[AES_STATE_W][AES_STATE_W], uint8_t out[AES_BLOCK_SIZE]) {
    // check on be
    #if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__ //?
    for (int r = 0; r < AES_STATE_W; r++) {
        for (int c = 0; c < AES_STATE_W; c++) {
            out[c+AES_STATE_W*r] = state_in[r][c];
        }
    }
    #else
    for (int r = 0; r < AES_STATE_W; r++) {
        for (int c = 0; c < AES_STATE_W; c++) {
            out[r+AES_STATE_W*c] = state_in[r][c];
        }
    }
    #endif
}


//#define AES_SBOX_CONST 0b01100011
//static inline uint8_t aes_sbox(uint8_t b) {
//    // binv = b~
//    uint8_t binv = galois_inverse(b);
//    uint8_t bout = 0;
//    uint8_t temp_bit = 0;
//    for (int i = 0; i < 8; i++) {
//        temp_bit = 
//            ((binv>>i)&1) ^ 
//            ((binv>>((i+4)%8))&1) ^ 
//            ((binv>>((i+5)%8))&1) ^ 
//            ((binv>>((i+6)%8))&1) ^ 
//            ((binv>>((i+7)%8))&1) ^ 
//            ((AES_SBOX_CONST>>i)&1);
//        bout |=  temp_bit << i;
//    }
//    return bout;
//}

static inline uint8_t aes_sbox(uint8_t b) {return aes_sbox_lookup[b];}
static inline void aes_subbytes(uint8_t state[AES_STATE_W][AES_STATE_W]) { // page 13(21)
    for (int x = 0; x < AES_STATE_W; x++) {
        for (int y = 0; y < AES_STATE_W; y++) {
            state[x][y] = aes_sbox(state[x][y]);
        }
    }
}

// note: can be done in-place but that doesn't provide any useful performance boost and is completely unreadable
static inline void aes_shiftrows(uint8_t state[AES_STATE_W][AES_STATE_W]) { // page 14(22)
    uint8_t state_out[AES_STATE_W][AES_STATE_W] = {0};
    for (int r = 0; r < AES_STATE_W; r++) {
        for (int c = 0; c < AES_STATE_W; c++) {
            state_out[r][c] = state[r][(c+r)%AES_STATE_W];
        }
    }
    memcpy(state, state_out, sizeof(state_out));
}

static inline void aes_mixcolumns(uint8_t state[AES_STATE_W][AES_STATE_W]) {
    static const uint8_t matrix_word[AES_WORD_SIZE] = {
        0x02, 0x01, 0x01, 0x03
    };
    uint8_t temp[AES_STATE_W] = {0};
    uint8_t temp_out[AES_STATE_W] = {0};

    for (int c = 0; c < AES_STATE_W; c++) {
        temp[0] = state[0][c];
        temp[1] = state[1][c];
        temp[2] = state[2][c];
        temp[3] = state[3][c];
        galois_fixed_mat_mult(temp, temp_out, matrix_word);
        state[0][c] = temp_out[0];
        state[1][c] = temp_out[1];
        state[2][c] = temp_out[2];
        state[3][c] = temp_out[3];
    }
}

static inline void aes_addroundkey(uint8_t state[AES_STATE_W][AES_STATE_W], const AES_WORD_TYPE * key_schedule, int round) {
    for (int c = 0; c < AES_STATE_W; c++) {
        #if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__ // i suspect this may be needed, don't have anywhere to test
        state[0][c] ^= (key_schedule[4*round + c]>>24)&0xFF;
        state[1][c] ^= (key_schedule[4*round + c]>>16)&0xFF;
        state[2][c] ^= (key_schedule[4*round + c]>>8)&0xFF;
        state[3][c] ^= (key_schedule[4*round + c]>>0)&0xFF;
        #else
        state[3][c] ^= (key_schedule[4*round + c]>>24)&0xFF;
        state[2][c] ^= (key_schedule[4*round + c]>>16)&0xFF;
        state[1][c] ^= (key_schedule[4*round + c]>>8)&0xFF;
        state[0][c] ^= (key_schedule[4*round + c]>>0)&0xFF;
        #endif
    }
}

static const AES_WORD_TYPE aes_round_keys_rcon_consts[11] = {// used indices start from 1
    0,
    0x01000000,
    0x02000000,
    0x04000000,
    0x08000000,
    0x10000000,
    0x20000000,
    0x40000000,
    0x80000000,
    0x1b000000,
    0x36000000,
};

static inline AES_WORD_TYPE aes_keyexpansion_rotword(AES_WORD_TYPE a) {
    return (a << 8) | (a >> 24);
}

static inline AES_WORD_TYPE aes_keyexpansion_subword(AES_WORD_TYPE a) {
    uint8_t * temparr = (uint8_t*)&a;
    temparr[0] = aes_sbox(temparr[0]);
    temparr[1] = aes_sbox(temparr[1]);
    temparr[2] = aes_sbox(temparr[2]);
    temparr[3] = aes_sbox(temparr[3]);
    return a;
};

static inline void aes_keyexpansion(const uint8_t * block_cipher_key, AES_WORD_TYPE * key_schedule, int nkey, int ke_rounds) { // see page 18(26)
    // 60% chance that this won't work on BE
    
    AES_WORD_TYPE temp = 0;
    for (int i = 0; i <= nkey - 1; i++) {
        key_schedule[i] = be32toh(*(uint32_t *)&block_cipher_key[AES_WORD_SIZE*i]);
        //memcpy(&key_schedule[i], &block_cipher_key[AES_WORD_SIZE*i], AES_WORD_SIZE);
    }
    for (int i = nkey; i <= 4*ke_rounds + 3; i++) {
        temp = key_schedule[i-1];
        if (i % nkey == 0) {
            temp = aes_keyexpansion_rotword(temp);
            temp = aes_keyexpansion_subword(temp) ^ aes_round_keys_rcon_consts[i/nkey];
        } else if (nkey > 6 && i % nkey == 4) {
            temp = aes_keyexpansion_subword(temp);
        }
        key_schedule[i] = key_schedule[i-nkey] ^ temp;
    }
}

static inline void print_state(const uint8_t state_in[AES_STATE_W][AES_STATE_W]) {
    for (int x = 0; x < AES_STATE_W; x++) {
        for (int y = 0; y < AES_STATE_W; y++) {
            printf("%02hhx ", state_in[x][y]);
        }
        printf("\n");
    }
}

static inline void print_round_key(const uint32_t * key) {
    for (int i = 0; i < 4; i++) {
        printf("%02hhx %02hhx %02hhx %02hhx\n", key[i]>>24, (key[i]>>16)&0xFF, (key[i]>>8)&0xFF, key[i]&0xFF);
    }
}

static void aes_internal_cipher(const uint8_t plain_data[AES_BLOCK_SIZE], uint8_t enc_data_out[AES_BLOCK_SIZE], int key_expansion_rounds, const uint8_t * block_cipher_key){
    uint8_t state[AES_STATE_W][AES_STATE_W] = {0};

    aes_bytes_to_state(state, plain_data);

    AES_WORD_TYPE key_schedule[4*(key_expansion_rounds + 1)];
    memset(key_schedule, 0, sizeof(key_schedule));

    switch (key_expansion_rounds) {
        case AES_128_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_128_NKEY, key_expansion_rounds);
            break;
        case AES_192_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_192_NKEY, key_expansion_rounds);
            break;
        case AES_256_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_256_NKEY, key_expansion_rounds);
            break;
        default: exit(1);
    }

    aes_addroundkey(state, key_schedule, 0);

    for (int round = 1; round <= key_expansion_rounds - 1; round ++) {
        aes_subbytes(state);
        aes_shiftrows(state);
        aes_mixcolumns(state);
        aes_addroundkey(state, key_schedule, round);
    }
    aes_subbytes(state);
    aes_shiftrows(state);
    aes_addroundkey(state, key_schedule, key_expansion_rounds);
    aes_state_to_bytes(state, enc_data_out);
}

static const uint8_t aes_invsbox_lookup[256] = {
    0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb,
    0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87, 0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb,
    0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d, 0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e,
    0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2, 0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25,
    0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92,
    0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda, 0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84,
    0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a, 0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06,
    0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02, 0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b,
    0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea, 0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73,
    0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85, 0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e,
    0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89, 0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b,
    0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20, 0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4,
    0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31, 0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f,
    0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d, 0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef,
    0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0, 0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61,
    0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26, 0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d
};

// won't implement, but invsbox is just switched inputs and outputs

#define MOD(x, M) ((((x)%(M))+(M))%(M))

static inline uint8_t aes_invsbox(uint8_t b) {return aes_invsbox_lookup[b];}
static inline void aes_invsubbytes(uint8_t state[AES_STATE_W][AES_STATE_W]) { // page 13(21)
    for (int x = 0; x < AES_STATE_W; x++) {
        for (int y = 0; y < AES_STATE_W; y++) {
            state[x][y] = aes_invsbox(state[x][y]);
        }
    }
}

// note: can be done in-place but that doesn't provide any useful performance boost and is completely unreadable
static inline void aes_invshiftrows(uint8_t state[AES_STATE_W][AES_STATE_W]) { // page 14(22)
    uint8_t state_out[AES_STATE_W][AES_STATE_W] = {0};
    for (int r = 0; r < AES_STATE_W; r++) {
        for (int c = 0; c < AES_STATE_W; c++) {
            state_out[r][c] = state[r][MOD(c-r,AES_STATE_W)];
        }
    }
    memcpy(state, state_out, sizeof(state_out));
}

static inline void aes_invmixcolumns(uint8_t state[AES_STATE_W][AES_STATE_W]) {
    static const uint8_t matrix_word[AES_WORD_SIZE] = {
        0x0e, 0x09, 0x0d, 0x0b
    };
    uint8_t temp[AES_STATE_W] = {0};
    uint8_t temp_out[AES_STATE_W] = {0};

    for (int c = 0; c < AES_STATE_W; c++) {
        temp[0] = state[0][c];
        temp[1] = state[1][c];
        temp[2] = state[2][c];
        temp[3] = state[3][c];
        galois_fixed_mat_mult(temp, temp_out, matrix_word);
        state[0][c] = temp_out[0];
        state[1][c] = temp_out[1];
        state[2][c] = temp_out[2];
        state[3][c] = temp_out[3];
    }
}

static void aes_internal_invcipher(const uint8_t enc_data[AES_BLOCK_SIZE], uint8_t plain_data_out[AES_BLOCK_SIZE], int key_expansion_rounds, const uint8_t * block_cipher_key) {
    uint8_t state[AES_STATE_W][AES_STATE_W] = {0};

    aes_bytes_to_state(state, enc_data);

    AES_WORD_TYPE key_schedule[4*(key_expansion_rounds + 1)];
    memset(key_schedule, 0, sizeof(key_schedule));

    switch (key_expansion_rounds) {
        case AES_128_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_128_NKEY, key_expansion_rounds);
            break;
        case AES_192_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_192_NKEY, key_expansion_rounds);
            break;
        case AES_256_KE_ROUNDS:
            aes_keyexpansion(block_cipher_key, key_schedule, AES_256_NKEY, key_expansion_rounds);
            break;
        default: exit(1);
    }

    aes_addroundkey(state, key_schedule, key_expansion_rounds);

    for (int round = key_expansion_rounds - 1; round >= 1; round --) {
        aes_invshiftrows(state);
        aes_invsubbytes(state);
        aes_addroundkey(state, key_schedule, round);
        aes_invmixcolumns(state);
    }
    aes_invshiftrows(state);
    aes_invsubbytes(state);
    aes_addroundkey(state, key_schedule, 0);
    aes_state_to_bytes(state, plain_data_out);
}

void aes_128_enc(const uint8_t plain_data[AES_BLOCK_SIZE],  uint8_t enc_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_128_KEY_LEN]) {
    aes_internal_cipher(plain_data, enc_data_out, AES_128_KE_ROUNDS, block_cipher_key);
}
void aes_128_dec(const uint8_t enc_data[AES_BLOCK_SIZE],  uint8_t plain_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_128_KEY_LEN]) {
    aes_internal_invcipher(enc_data, plain_data_out, AES_128_KE_ROUNDS, block_cipher_key);
}

void aes_192_enc(const uint8_t plain_data[AES_BLOCK_SIZE], uint8_t enc_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_192_KEY_LEN]) {
    aes_internal_cipher(plain_data, enc_data_out, AES_192_KE_ROUNDS, block_cipher_key);
}
void aes_192_dec(const uint8_t enc_data[AES_BLOCK_SIZE],  uint8_t plain_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_192_KEY_LEN]) {
    aes_internal_invcipher(enc_data, plain_data_out, AES_192_KE_ROUNDS, block_cipher_key);
}

void aes_256_enc(const uint8_t plain_data[AES_BLOCK_SIZE], uint8_t enc_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_256_KEY_LEN]) {
    aes_internal_cipher(plain_data, enc_data_out, AES_256_KE_ROUNDS, block_cipher_key);
}
void aes_256_dec(const uint8_t enc_data[AES_BLOCK_SIZE],  uint8_t plain_data_out[AES_BLOCK_SIZE], const uint8_t block_cipher_key[AES_256_KEY_LEN]) {
    aes_internal_invcipher(enc_data, plain_data_out, AES_256_KE_ROUNDS, block_cipher_key);
}
